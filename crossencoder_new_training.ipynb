{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f6460d-c4ef-442a-b216-930b44c701d6",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "de7c9e27-2839-4ea4-8d03-4ae2f1219b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 19:26:32,787 - __main__ - INFO - This is an info message\n",
      "2024-02-27 19:26:32,787 - __main__ - INFO - This is an info message\n",
      "2024-02-27 19:26:32,787 - __main__ - INFO - This is an info message\n",
      "2024-02-27 19:26:32,787 - __main__ - INFO - This is an info message\n",
      "2024-02-27 19:26:32,787 - __main__ - INFO - This is an info message\n",
      "2024-02-27 19:26:32,787 - __main__ - INFO - This is an info message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/27/2024 19:26:32 - INFO - __main__ - This is an info message\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "console_handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(formatter)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Log some messages\n",
    "\n",
    "logger.info('This is an info message')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "824ef6b8-08b1-42ae-adb5-2606108b6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fb2c19-eca6-4a13-b556-c09a55c28700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import numpy as np\n",
    "# Filter out all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ed3e0-69d2-4dc0-a12b-ad5e1bd2d5b1",
   "metadata": {},
   "source": [
    "## Data Loading and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54fdc066-6718-4382-ac09-3db2ff8c327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_data = pd.read_csv(\"/Users/603642/Downloads/crossencoder_train_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "54a4f25b-dd11-4a0c-8d6b-82dd5690a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# km_data['final'] = km_data['question_x']+','+ km_data['question_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf10c876-dba3-4f00-a142-4d8a34d4f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_data.columns = [\"sentence1\",\"sentence2\",\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "818eaf15-b57d-4c93-baed-9497e95da832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_vrb = pd.read_csv(\"vrb_master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "70ba67d8-5236-4c8f-a6d6-96e300b7b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_vrb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "cbbbf66b-e800-497b-9957-f9e75909529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_vrb[[\"response_id\",\"_id_x\",\"_id_y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5116d528-3b7d-4548-9e42-9214fba6e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_question = pd.read_csv(\"id_questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5b1f451c-8ccd-4483-9648-bf198e24dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f002b010-a5fd-429b-b7f4-32066c9cac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_vrb[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae0816-1d68-4c7f-89d7-92cb3ae1649e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0e492-8f70-4a54-ae87-e1ebf1365a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbc2688-821e-4f85-9a57-1632df6bb03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>what is the UMNR fee</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>what is the term entry to unhook a ticket</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>how to unhook a tkt in term</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sentence1  \\\n",
       "0  what is the unaccompanied minor fee   \n",
       "1  what is the unaccompanied minor fee   \n",
       "2  what is the unaccompanied minor fee   \n",
       "3  what is the unaccompanied minor fee   \n",
       "4  what is the unaccompanied minor fee   \n",
       "\n",
       "                                   sentence2  labels  \n",
       "0     how much is a UMNR fee from jfk to acc     1.0  \n",
       "1     how much is a UMNR fee from jfk to acc     1.0  \n",
       "2                       what is the UMNR fee     1.0  \n",
       "3  what is the term entry to unhook a ticket     0.0  \n",
       "4                how to unhook a tkt in term     0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba335f81-ab96-44b9-ac84-d033958f7435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0.0    1287154\n",
       "1.0       6202\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_data.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c5582db-1ecf-4a7d-bc94-d5b760262fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence1    0\n",
       "sentence2    0\n",
       "labels       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0a52f341-a91b-4147-84bb-7c44276fce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# km_data.columns = [\"sentence1\",\"sentence2\",\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda7a37c-6aa7-42a4-b0ae-3f454b245bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>what is the term entry to unhook a ticket</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>how to unhook a tkt in term</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>entry to unhook ticket in term</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>how to unhook a ticket in term</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>how do you unhook a ticket in DL TERM</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293349</th>\n",
       "      <td>award travel on kenya airways</td>\n",
       "      <td>ecredit use on other person</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293350</th>\n",
       "      <td>award travel on kenya airways</td>\n",
       "      <td>Can ecredits be transferred to other passenger...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293351</th>\n",
       "      <td>award travel on kenya airways</td>\n",
       "      <td>ecredit use on other person</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293352</th>\n",
       "      <td>award travel on kenya airways</td>\n",
       "      <td>latam carry on</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293353</th>\n",
       "      <td>award travel on kenya airways</td>\n",
       "      <td>latam carry on bag</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1287154 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sentence1  \\\n",
       "3        what is the unaccompanied minor fee   \n",
       "4        what is the unaccompanied minor fee   \n",
       "5        what is the unaccompanied minor fee   \n",
       "6        what is the unaccompanied minor fee   \n",
       "7        what is the unaccompanied minor fee   \n",
       "...                                      ...   \n",
       "1293349        award travel on kenya airways   \n",
       "1293350        award travel on kenya airways   \n",
       "1293351        award travel on kenya airways   \n",
       "1293352        award travel on kenya airways   \n",
       "1293353        award travel on kenya airways   \n",
       "\n",
       "                                                 sentence2  labels  \n",
       "3                what is the term entry to unhook a ticket     0.0  \n",
       "4                              how to unhook a tkt in term     0.0  \n",
       "5                           entry to unhook ticket in term     0.0  \n",
       "6                           how to unhook a ticket in term     0.0  \n",
       "7                    how do you unhook a ticket in DL TERM     0.0  \n",
       "...                                                    ...     ...  \n",
       "1293349                        ecredit use on other person     0.0  \n",
       "1293350  Can ecredits be transferred to other passenger...     0.0  \n",
       "1293351                        ecredit use on other person     0.0  \n",
       "1293352                                     latam carry on     0.0  \n",
       "1293353                                 latam carry on bag     0.0  \n",
       "\n",
       "[1287154 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_data[km_data.labels==0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92cf2d-44de-41c0-80bd-279155b7df81",
   "metadata": {},
   "source": [
    "## Balance the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a502e4d-73c4-4e49-b572-6a25b2b6d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df = km_data[km_data.labels==0.0]\n",
    "positive_df = km_data[km_data.labels==1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4072c7c7-9571-4214-a11f-c729eab2c531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6202, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c322288e-e894-4934-bbe7-c2eef30a9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_km = pd.concat([negative_df.iloc[:6202],positive_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4da8d7c2-6e27-49ae-ba44-86b61b5e343d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0.0    6202\n",
       "1.0    6202\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_km.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a6a7561-3861-476d-972a-4a71299b3775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence1', 'sentence2', 'labels'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_km.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ccd978c8-0271-4f47-8bd1-6ecdc1654d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required_df = balance_km[[\"pair\",\"labels\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f043e-e0d9-4f55-bec5-d78ba1a2d8aa",
   "metadata": {},
   "source": [
    "## Train,Test,Validation Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bd2fd725-80e8-470e-a244-b41ab189bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7ffad153-df80-41eb-a24d-1e5355b91885",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(balance_km,test_size=0.2,random_state=42)\n",
    "test,validation = train_test_split(test,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f48b87b4-4076-4902-ae0d-e3230e8f4d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9923, 3)\n",
      "(1240, 3)\n",
      "(1241, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "54679026-cb2c-42d0-a782-cdd2ac111b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[:2000]\n",
    "test = test[:400]\n",
    "validation = validation[:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aea6674-79bd-44ef-b2fa-fe3972d97318",
   "metadata": {},
   "source": [
    "## Convert Data to HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b0397ba8-54ce-4e41-bc82-29c94130eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "16b2ac99-a288-494b-8b50-e71afad6647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "val_dataset = Dataset.from_pandas(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a154a3df-6708-4db6-acbe-854248d78dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>722316</th>\n",
       "      <td>GUC and RUC</td>\n",
       "      <td>How to reapply reg certs?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>how to unhook a tkt in term</td>\n",
       "      <td>what is the nearest airport to jfk</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>What is wheelchair</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>what are transportation rules for human organs</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4420</th>\n",
       "      <td>what is the UMNR fee</td>\n",
       "      <td>what are the rules of TakeOff 15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631</th>\n",
       "      <td>what is the term entry to unhook a ticket</td>\n",
       "      <td>HOW TO DOCUMENT MISSING MILES</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287779</th>\n",
       "      <td>who can go through sky priority</td>\n",
       "      <td>how do I get sky priority</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010119</th>\n",
       "      <td>can bassinets BE reserved on delta flight</td>\n",
       "      <td>can bassinets BE reserved on delta flighta</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378767</th>\n",
       "      <td>does delta accept pets in cabin</td>\n",
       "      <td>bring dog on plane</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938453</th>\n",
       "      <td>are ebikes allowed</td>\n",
       "      <td>can i take my electric bike on the plane</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sentence1  \\\n",
       "722316                                 GUC and RUC   \n",
       "5906                   how to unhook a tkt in term   \n",
       "3108        how much is a UMNR fee from jfk to acc   \n",
       "686            what is the unaccompanied minor fee   \n",
       "4420                          what is the UMNR fee   \n",
       "...                                            ...   \n",
       "5631     what is the term entry to unhook a ticket   \n",
       "287779             who can go through sky priority   \n",
       "1010119  can bassinets BE reserved on delta flight   \n",
       "378767             does delta accept pets in cabin   \n",
       "938453                          are ebikes allowed   \n",
       "\n",
       "                                              sentence2  labels  \n",
       "722316                        How to reapply reg certs?     1.0  \n",
       "5906                 what is the nearest airport to jfk     0.0  \n",
       "3108                                 What is wheelchair     0.0  \n",
       "686      what are transportation rules for human organs     0.0  \n",
       "4420                   what are the rules of TakeOff 15     0.0  \n",
       "...                                                 ...     ...  \n",
       "5631                      HOW TO DOCUMENT MISSING MILES     0.0  \n",
       "287779                        how do I get sky priority     1.0  \n",
       "1010119      can bassinets BE reserved on delta flighta     1.0  \n",
       "378767                               bring dog on plane     1.0  \n",
       "938453         can i take my electric bike on the plane     1.0  \n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "40e61ba6-7eb6-44a2-a26f-2165d29b88a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Replace this with your actual data loading code\n",
    "raw_datasets = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train),\n",
    "    'validation': Dataset.from_pandas(validation),\n",
    "    # 'test':Dataset.from_pandas(test_dataset)\n",
    "    \n",
    "})\n",
    "\n",
    "# # Define your preprocess function\n",
    "# def preprocess_function(examples):\n",
    "#     return tokenizer(examples['text1'], examples['text2'], truncation=True)\n",
    "\n",
    "# # Apply the preprocess function\n",
    "# tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db8f2dc-fbb3-4a9b-8156-31b1678fae59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2965a804-b21c-4556-82e3-081f571217c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset( {'train': train_datset, \n",
    "#                                           'validation': val_datset,\n",
    "#                                           'test': test_datset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a168154-82a8-4269-a772-e027dba3e802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6d2838b-adc1-469c-bbba-1b0314b283c4",
   "metadata": {},
   "source": [
    "## Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7db04df3-7aad-4c08-bcd8-a8d3305f597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)  # Use num_labels=1 for regression tasks like STS-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "61ef3077-95a6-4218-a3ee-2bbfd9d83b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples):\n",
    "    return tokenizer(examples['sentence1'], examples['sentence2'], truncation=True, padding='max_length',max_length=128)\n",
    "\n",
    "# def encode(examples):\n",
    "#     return tokenizer(examples['pair'], truncation=True, padding='max_length',max_length=128)\n",
    "# encoded_dataset = dataset.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2ca394ce-23ae-4957-b955-64e1bddd832b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc58d0f02a043cd9f310482c75bf4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de8590a41594fcba3f56912a5f49335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34913b7b7e243f6b9a34d6557a60752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_encoded = train_dataset.map(encode, batched=True)\n",
    "val_encoded = val_dataset.map(encode, batched=True)\n",
    "test_encoded = test_dataset.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0e80ccaf-8faf-4833-ae4e-f1a7743f6e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_encoded.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8a54eb1e-2ce4-4004-9b45-c451b2e3f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# total_batch_size = 84\n",
    "# num_cpu_cores = os.cpu_count()\n",
    "# num_cpu_cores\n",
    "# per_device_train_batch_size = total_batch_size // num_cpu_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "98402410-e97a-4c69-8fbe-cd790f636246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per_device_train_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c27ac3-f6f8-48f3-8d69-b9bfbb7145ff",
   "metadata": {},
   "source": [
    "## Model Finetuning : Training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "83c8b57c-9202-4b73-ac27-f5385cfd058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./crossencoder-marco-MiniLM-L-6-v2-refine',          # Output directory for the model checkpoints\n",
    "    num_train_epochs=3,              # Number of training epochs\n",
    "    per_device_train_batch_size=16,   # Batch size for training\n",
    "    per_device_eval_batch_size=16,    # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # Weight decay if we apply some\n",
    "    logging_dir='./logs',            # Directory for storing logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",     # Evaluate after each epoch\n",
    "    lr_scheduler_type='cosine',\n",
    "    learning_rate=5e-5\n",
    "    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239c7ea-451a-4ad3-be8b-9bfa461f23e6",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "676195ad-6416-49f3-be0b-53af4f948a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     accuracy = np.mean(predictions == labels)\n",
    "#     return {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     accuracy = accuracy_score(labels, predictions)\n",
    "#     precision = precision_score(labels, predictions, average='binary')  # Use 'micro', 'macro', or 'weighted' for multiclass\n",
    "#     recall = recall_score(labels, predictions, average='binary')  # Use 'micro', 'macro', or 'weighted' for multiclass\n",
    "    \n",
    "#     return {\n",
    "#         \"accuracy\": accuracy,\n",
    "#         \"precision\": precision,\n",
    "#         \"recall\": recall\n",
    "#     }\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred, threshold=0.75):\n",
    "    logits, labels = eval_pred\n",
    "    # Convert logits to class predictions based on the threshold\n",
    "    predictions = (logits >= threshold).astype(int)\n",
    "    # logger.info(logits)\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions)\n",
    "    recall = recall_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }\n",
    "\n",
    "\n",
    "# logits = torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\n",
    "# predictions = torch.argmax(logits,dim=-1)\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d338fd3b-5506-4e3c-a81d-1e29b9f8898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=encoded_dataset['train'],\n",
    "#     eval_dataset=encoded_dataset['validation'],\n",
    "#     tokenizer=tokenizer\n",
    "# )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_encoded,\n",
    "    eval_dataset=val_encoded,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "97552071-56fa-41f0-a4cc-e8b4bf70e34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 01:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.428392</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>0.723404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.096566</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>0.020387</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=16.94432011508942, metrics={'train_runtime': 97.3382, 'train_samples_per_second': 61.641, 'train_steps_per_second': 3.853, 'total_flos': 49746940416000.0, 'train_loss': 16.94432011508942, 'epoch': 3.0})"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "940aa0e9-c5ed-40e9-bc9a-83c15f6ce653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.016239233314990997,\n",
       " 'eval_accuracy': 0.995,\n",
       " 'eval_precision': 1.0,\n",
       " 'eval_recall': 0.9901960784313726,\n",
       " 'eval_runtime': 0.8736,\n",
       " 'eval_samples_per_second': 457.894,\n",
       " 'eval_steps_per_second': 28.618,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.evaluate(encoded_dataset['test'])\n",
    "trainer.evaluate(test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b149dd1-62c0-4bf0-8e64-13995e93e094",
   "metadata": {},
   "source": [
    "## Save the model to Hub & Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd074e50-2845-4dd5-8a8c-dfcedc9f419c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./MiniLM-L-6-v2-refine/tokenizer_config.json',\n",
       " './MiniLM-L-6-v2-refine/special_tokens_map.json',\n",
       " './MiniLM-L-6-v2-refine/vocab.txt',\n",
       " './MiniLM-L-6-v2-refine/added_tokens.json',\n",
       " './MiniLM-L-6-v2-refine/tokenizer.json')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./MiniLM-L-6-v2-refine')\n",
    "tokenizer.save_pretrained('./MiniLM-L-6-v2-refine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "70a82a6b-0702-4727-be26-97f0e5332540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4cfa132036454086d2d6ffb9c03af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b57a1cf861845d8895ca29cbeab946a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfeaa1710984d94b1b8377a0c319cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/srmishra/crossencoder-marco-MiniLM-L-6-v2-refine/commit/e4f0add2f5def32c7d4047423553ca9bb4991b7a', commit_message='End of training', commit_description='', oid='e4f0add2f5def32c7d4047423553ca9bb4991b7a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512de995-b408-4b52-94b3-e3abdb8f8a5d",
   "metadata": {},
   "source": [
    "## Tensorboard Training Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "87cafaec-a76d-4825-b791-3afb91362692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.16.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e2801e-ac7b-4963-a859-770e0afac594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad035b-626f-4803-ae98-ae0a0d319117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab3c98ba-b10f-4ad5-89ce-c7723a2fece7",
   "metadata": {},
   "source": [
    "## Load the Finetunes Model IF Instance is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3ca280ff-f5a3-4e5d-88fe-bbcf80e005d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('srmishra/crossencoder-airline-refine')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('srmishra/crossencoder-airline-refine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0247da-7cda-4e3e-804c-32605dbdb224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1a8a3906-157c-472e-b273-be3d1f1215f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pjbhaumik/crossencoder-km1\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"pjbhaumik/crossencoder-km1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd88d68a-7892-4e1e-adb4-bbc4e5c6940b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10276299-5d1f-4ea1-be5f-9be6d5e31f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb8cca6-4543-4f26-a6a4-75dcf70ebc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2979dd47-0862-4938-98d9-e931577dc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentences(sentence1, sentence2):\n",
    "    return tokenizer(sentence1, sentence2, return_tensors='pt', truncation=True, padding='max_length')\n",
    "\n",
    "# # Example pairs of sentences\n",
    "# sentence_pairs = [\n",
    "#     (\"dog a pet animal.\", \"cat is pet animal.\"),\n",
    "#     (\"We can take pet in main cabin.\", \"Pet in main cabin requires vaccine certificate\")\n",
    "# ]\n",
    "\n",
    "# encoded_inputs = [encode_sentences(pair[0], pair[1]) for pair in sentence_pairs]\n",
    "\n",
    "# def encode_sentences(examples):\n",
    "#     return tokenizer(examples['pair'], truncation=True, padding='max_length',max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bbea15-ac67-4f82-9578-45b868c9f2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b474111-ae1b-4dc7-91a7-d53dcc3cb152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example pairs of sentences\n",
    "# sentence_pairs = [\n",
    "#     (\"dog a pet animal.\", \"cat is pet animal.\"),\n",
    "#     (\"We can take pet in main cabin.\", \"Pet in main cabin requires vaccine certificate\")\n",
    "# ]\n",
    "\n",
    "# encoded_inputs = [encode_sentences(pair[0], pair[1]) for pair in sentence_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fb0e39b4-c1e3-4fb0-9292-47de9da708f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_dataset.to_pandas()[[\"sentence1\",\"sentence2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d2b783c8-60ad-463e-bdbd-dad602df1e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>miles cacelation of basic economy</td>\n",
       "      <td>basic economy cancel and redeposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>is the customer care line open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>which seats occupy bassinets</td>\n",
       "      <td>does my flight from ATL to LHR have a bassinet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>how long does it take to reopen a global upgra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>SYMILES ACCOUNT UNDER AUDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>can i travel internationally without a passport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>what is the UMNR fee</td>\n",
       "      <td>changing flights rules day of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>how to earn status</td>\n",
       "      <td>GOLD MEDALLION QUALIFICATIONS FOR 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>what is the minimum connection time for an int...</td>\n",
       "      <td>what is the minimum connection time in msp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>what is the term entry to unhook a ticket</td>\n",
       "      <td>where are the baggage fee charts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence1  \\\n",
       "0                    miles cacelation of basic economy   \n",
       "1               how much is a UMNR fee from jfk to acc   \n",
       "2                         which seats occupy bassinets   \n",
       "3               how much is a UMNR fee from jfk to acc   \n",
       "4                  what is the unaccompanied minor fee   \n",
       "..                                                 ...   \n",
       "395             how much is a UMNR fee from jfk to acc   \n",
       "396                               what is the UMNR fee   \n",
       "397                                 how to earn status   \n",
       "398  what is the minimum connection time for an int...   \n",
       "399          what is the term entry to unhook a ticket   \n",
       "\n",
       "                                             sentence2  \n",
       "0                   basic economy cancel and redeposit  \n",
       "1                       is the customer care line open  \n",
       "2       does my flight from ATL to LHR have a bassinet  \n",
       "3    how long does it take to reopen a global upgra...  \n",
       "4                          SYMILES ACCOUNT UNDER AUDIT  \n",
       "..                                                 ...  \n",
       "395    can i travel internationally without a passport  \n",
       "396                      changing flights rules day of  \n",
       "397             GOLD MEDALLION QUALIFICATIONS FOR 2024  \n",
       "398         what is the minimum connection time in msp  \n",
       "399                   where are the baggage fee charts  \n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "89cdfbbb-9f55-4c85-ae84-da12b9e779fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pairs = list(zip(test_df[\"sentence1\"],test_df[\"sentence2\"]))\n",
    "encoded_inputs = [encode_sentences(pair[0], pair[1]) for pair in sentence_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2e42a30f-901a-4622-8c62-af888c12410a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2661, 6187, 29109, 3370, 1997, 3937, 4610, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"miles cacelation of basic economy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61f2f774-2393-43b2-8554-a265140c2d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_inputs[0].input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b416caf-75be-434b-bfb2-30bfafbaf023",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4550b711-116c-4e41-b4d3-31e5fe32eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.sigmoid([1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "700a337f-7883-4ccd-9a31-f50e43feb932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dffed889-e372-4d54-adc4-d9a9e157b070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=384, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e501379b-28a6-4bae-972b-88ac9a0ebbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(encoded_inputs, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "aed74b6f-03aa-4f5b-9f11-c3513c9216c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdba897-536f-4840-89db-240b7e078e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Put the model in evaluation mode\n",
    "# model.cuda()\n",
    "# model.eval()\n",
    "# torch.no_grad()\n",
    "# # Predictions list\n",
    "# predictions = []\n",
    "\n",
    "# for i, batch in enumerate(batches):\n",
    "#     encoded_inputs = tokenizer(batch, return_tensors='pt', truncation=True, padding='max_length').to(\"cuda\")\n",
    "#     outputs = model(**encoded_inputs)\n",
    "#     scores = [score.item() for score in outputs.logits.squeeze()]\n",
    "#     predictions += scores\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "# len(predictions) == len(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cd047d3-726f-40dd-822c-9a4ad1d9bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for batch in test_loader:\n",
    "#         print(batch)\n",
    "#         # Move batch to device\n",
    "#         batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "#         # Forward pass\n",
    "#         outputs = model(**batch)\n",
    "#         logits = outputs.logits\n",
    "#         print(logits)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d7af3-5209-4b5d-b70d-50c2952b48f4",
   "metadata": {},
   "source": [
    "## Predict Individual Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5b2594a4-447d-40b6-9a2b-925f9188da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crossencoder_output(tokenizer,model,encoded_inputs):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Predictions list\n",
    "    predictions = []\n",
    "    \n",
    "    # Disable gradient calculation for inference\n",
    "    # encoded_inputs = encoded_inputs[:10]\n",
    "    with torch.no_grad():\n",
    "        for encoded_input in tqdm(encoded_inputs):\n",
    "            # Move the tensors to the same device as the model\n",
    "            encoded_input = {k: v.to(model.device) for k, v in encoded_input.items()}\n",
    "            \n",
    "            # Get the model outputs\n",
    "            outputs = model(**encoded_input)\n",
    "            # print(f\"RAW OUTPUT: {outputs}\")\n",
    "            # The outputs are logits, get the score by applying the appropriate activation function\n",
    "            # For regression tasks (like STS-B), you can directly use the output value as the score\n",
    "            # For classification tasks, apply a softmax function to get probabilities\n",
    "            score = outputs.logits.squeeze().item()\n",
    "            # This will give sigmoid output like Sentence-Transformer\n",
    "            # score = torch.sigmoid(outputs.logits)[:, 0]\n",
    "            predictions.append(score)\n",
    "    \n",
    "    # Now `predictions` holds the similarity scores for each pair of sentences\n",
    "    # print(predictions)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# #Load from Local\n",
    "# tokenizer_local = AutoTokenizer.from_pretrained('./crossencoder_km_tinybert-model')\n",
    "# model_local = AutoModelForSequenceClassification.from_pretrained('./crossencoder_km_tinybert-model')\n",
    "\n",
    "# # Load from Hub\n",
    "# tokenizer_hub = AutoTokenizer.from_pretrained(\"srmishra/crossencoder-tynybert-km1\")\n",
    "# model_hub = AutoModelForSequenceClassification.from_pretrained(\"srmishra/crossencoder-tynybert-km1\")\n",
    "\n",
    "# def encode_sentences(sentence1, sentence2,tokenizer):\n",
    "#     return tokenizer(sentence1, sentence2, return_tensors='pt', truncation=True, padding='max_length')\n",
    "\n",
    "\n",
    "# sentence_pairs = [\n",
    "#     (\"What is the PETC eligibility\", \"can i bring a kitten on my flight from ATL to SLC\"),\n",
    "#     (\"what is the UMNR fee\", \"how many pets can i have\")\n",
    "# ]\n",
    "\n",
    "# encoded_inputs_local = [encode_sentences(pair[0], pair[1],tokenizer_local) for pair in sentence_pairs]\n",
    "# encoded_inputs_hub = [encode_sentences(pair[0], pair[1],tokenizer_hub) for pair in sentence_pairs]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0c955-48e1-4eb1-9ae0-b4a8ca9baf54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0d48c-2530-4795-a510-3fa8aa5f32d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "518fed25-21a2-4101-aff3-ede0373203df",
   "metadata": {},
   "source": [
    "## Prediction through Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "044cff4a-9f8e-4f7e-9bbc-2bdf61ec4c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs = test_dataset.to_pandas()[[\"sentence1\", \"sentence2\"]].apply(lambda x: (x[\"sentence1\"], x[\"sentence1\"]), axis = 1).to_list()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# del test_encoded\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99cda388-8f42-482d-802b-14c3cd3559f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "num_batches = (len(test_pairs) // batch_size)\n",
    "if len(test_pairs) % batch_size:\n",
    "    num_batches += 1\n",
    "\n",
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f01a3be2-3bb7-4c83-a5c9-49c958d47224",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [test_pairs[x*batch_size:(x+1)*batch_size] for x in range(num_batches)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba3f0ea-23fa-45c4-8516-5bc4950444c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "534d502f-f531-4e5f-aebf-8f29a437086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the model in evaluation mode\n",
    "# model.cuda()\n",
    "model.eval()\n",
    "torch.no_grad()\n",
    "# Predictions list\n",
    "predictions = []\n",
    "\n",
    "for i, batch in enumerate(tqdm(batches)):\n",
    "    encoded_inputs = tokenizer(batch, return_tensors='pt', truncation=True, padding='max_length').to(device)\n",
    "    outputs = model(**encoded_inputs)\n",
    "    # print(outputs)\n",
    "    if outputs.logits.squeeze().shape:\n",
    "        # print(outputs.logits.squeeze().shape)\n",
    "        predictions += [score.item() for score in outputs.logits.squeeze()]\n",
    "        # print(predictions)\n",
    "    else:\n",
    "        predictions += [outputs.logits.squeeze().item()]\n",
    "    \n",
    "    del encoded_inputs, outputs\n",
    "    # torch.cuda.empty_cache()\n",
    "        \n",
    "    gc.collect()\n",
    "  \n",
    "   \n",
    "len(predictions) == len(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "36d3d030-7a03-4985-8a62-3b3c5351c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = test_dataset.to_pandas()[[\"sentence1\",\"sentence2\",\"labels\"]]\n",
    "predicted_df[\"similar_score\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b96bbbc9-0066-4f19-9de4-021ff91de1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    400.000000\n",
       "mean       3.545358\n",
       "std        0.048562\n",
       "min        3.291201\n",
       "25%        3.523601\n",
       "50%        3.560787\n",
       "75%        3.568765\n",
       "max        3.653357\n",
       "Name: similar_score, dtype: float64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df['similar_score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a302c9-b6d6-477d-a521-859213305aa9",
   "metadata": {},
   "source": [
    "## Measure the Performance : Precision, Recall, F1 Score, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "421d63c2-4745-4199-866a-de1c15b19f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline precision: 0.4479 \n",
      "baseline recall: 0.7794 \n",
      "baseline accuracy: 0.3975 \n",
      "baseline f1: 0.5689\n"
     ]
    }
   ],
   "source": [
    "predicted_df['binarized'] = predicted_df['similar_score'].apply(lambda x: 1.0 if x > 3.5 else 0)\n",
    "base_precision = precision_score(predicted_df['labels'], predicted_df['binarized'])\n",
    "base_recall = recall_score(predicted_df['labels'], predicted_df['binarized'])\n",
    "base_accuracy = accuracy_score(predicted_df['labels'], predicted_df['binarized'])\n",
    "base_f1 = f1_score(predicted_df['labels'], predicted_df['binarized'])\n",
    "print(f'baseline precision: {base_precision:.4f} \\nbaseline recall: {base_recall:.4f} \\nbaseline accuracy: {base_accuracy:.4f} \\nbaseline f1: {base_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d433e9a-9c72-407a-8cc0-b8e257b195e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82715cc-e17b-448e-8c3d-390485741094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize the sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Suppose we have the following two questions\n",
    "question1 = \"How do I cook a perfect boiled egg?\"\n",
    "question2 = \"What's the best way to boil an egg?\"\n",
    "\n",
    "# Convert questions into embeddings\n",
    "q1_vector = model.encode(question1)\n",
    "q2_vector = model.encode(question2)\n",
    "\n",
    "# Create a FAISS index (for this example, we'll use a flat L2 index)\n",
    "dimension = q1_vector.shape[0]  # Dimension of the vectors\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Since we are only comparing two questions, we'll add both to the index\n",
    "index.add(np.array([q1_vector, q2_vector]))\n",
    "\n",
    "# To find the similarity, search the index\n",
    "# Here, k is the number of nearest neighbors to find; k=2 in this case\n",
    "# because we are only comparing two vectors\n",
    "k = 2\n",
    "D, I = index.search(np.array([q1_vector]), k)\n",
    "\n",
    "# D contains the distances, and I contains the indices of the nearest vectors\n",
    "print(f\"Distances: {D.flatten()}\")\n",
    "print(f\"Indices: {I.flatten()}\")\n",
    "\n",
    "# The distance of q1_vector to itself will be 0, the distance to q2_vector will indicate their similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774a8a5-51f3-4876-8610-137647799b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199c853-33be-4183-8902-525106e76705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d0258-8717-44ac-8cae-9d60f94dc7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f687f1f-6372-4a5d-b51b-7ae468806e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5b6cc68a-0d33-4fb3-b676-356b830ae145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.052358865737915, -0.009607994928956032]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_crossencoder_output(tokenizer_local,model_local,encoded_inputs_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c2d9e5ba-d219-4d1c-988b-4c4ae1a7efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 12.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.052358865737915, -0.009607994928956032]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_crossencoder_output(tokenizer_hub,model_hub,encoded_inputs_hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9854859e-c340-4578-9bb9-d9a059c90d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 400/400 [00:51<00:00,  7.72it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = get_crossencoder_output(tokenizer,model,encoded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c915bf6-b92c-4056-a99f-2e8eb62426c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = test_dataset.to_pandas()[[\"sentence1\",\"sentence2\",\"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "19c98e04-8356-4f0e-b459-559cc1f74a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df[\"predicted_score\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e1e5b2e-775e-40c7-93a6-8309d0712236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>labels</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>miles cacelation of basic economy</td>\n",
       "      <td>basic economy cancel and redeposit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.104069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>is the customer care line open</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>which seats occupy bassinets</td>\n",
       "      <td>does my flight from ATL to LHR have a bassinet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.062014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>how long does it take to reopen a global upgra...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.063898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>SYMILES ACCOUNT UNDER AUDIT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.102140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>can i travel internationally without a passport</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.158105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>what is the UMNR fee</td>\n",
       "      <td>changing flights rules day of</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.231820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>how to earn status</td>\n",
       "      <td>GOLD MEDALLION QUALIFICATIONS FOR 2024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>what is the minimum connection time for an int...</td>\n",
       "      <td>what is the minimum connection time in msp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.362267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>what is the term entry to unhook a ticket</td>\n",
       "      <td>where are the baggage fee charts</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.039016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence1  \\\n",
       "0                    miles cacelation of basic economy   \n",
       "1               how much is a UMNR fee from jfk to acc   \n",
       "2                         which seats occupy bassinets   \n",
       "3               how much is a UMNR fee from jfk to acc   \n",
       "4                  what is the unaccompanied minor fee   \n",
       "..                                                 ...   \n",
       "395             how much is a UMNR fee from jfk to acc   \n",
       "396                               what is the UMNR fee   \n",
       "397                                 how to earn status   \n",
       "398  what is the minimum connection time for an int...   \n",
       "399          what is the term entry to unhook a ticket   \n",
       "\n",
       "                                             sentence2  labels  \\\n",
       "0                   basic economy cancel and redeposit     1.0   \n",
       "1                       is the customer care line open     0.0   \n",
       "2       does my flight from ATL to LHR have a bassinet     1.0   \n",
       "3    how long does it take to reopen a global upgra...     0.0   \n",
       "4                          SYMILES ACCOUNT UNDER AUDIT     0.0   \n",
       "..                                                 ...     ...   \n",
       "395    can i travel internationally without a passport     0.0   \n",
       "396                      changing flights rules day of     0.0   \n",
       "397             GOLD MEDALLION QUALIFICATIONS FOR 2024     1.0   \n",
       "398         what is the minimum connection time in msp     1.0   \n",
       "399                   where are the baggage fee charts     0.0   \n",
       "\n",
       "     predicted_score  \n",
       "0           1.104069  \n",
       "1           0.021331  \n",
       "2           1.062014  \n",
       "3          -0.063898  \n",
       "4          -0.102140  \n",
       "..               ...  \n",
       "395        -0.158105  \n",
       "396        -0.231820  \n",
       "397         0.957206  \n",
       "398         1.362267  \n",
       "399        -0.039016  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b10c318-aef0-45a5-a364-a81de21c8705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    400.000000\n",
       "mean       0.520870\n",
       "std        0.612219\n",
       "min       -0.384372\n",
       "25%       -0.052355\n",
       "50%        0.555799\n",
       "75%        1.084717\n",
       "max        2.355689\n",
       "Name: predicted_score, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df['predicted_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb77e892-382c-41fc-8a33-fd194fa771a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline precision: 1.0000 \n",
      "baseline recall: 0.9804 \n",
      "baseline accuracy: 0.9900 \n",
      "baseline f1: 0.9901\n"
     ]
    }
   ],
   "source": [
    "predicted_df['binarized'] = predicted_df['predicted_score'].apply(lambda x: 1.0 if x > 0.56 else 0)\n",
    "base_precision = precision_score(predicted_df['labels'], predicted_df['binarized'])\n",
    "base_recall = recall_score(predicted_df['labels'], predicted_df['binarized'])\n",
    "base_accuracy = accuracy_score(predicted_df['labels'], predicted_df['binarized'])\n",
    "base_f1 = f1_score(predicted_df['labels'], predicted_df['binarized'])\n",
    "print(f'baseline precision: {base_precision:.4f} \\nbaseline recall: {base_recall:.4f} \\nbaseline accuracy: {base_accuracy:.4f} \\nbaseline f1: {base_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ff432-9740-41de-8c86-a73da59ee378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7ec71-d72a-459b-b9f4-f93e92b31c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e955e7d-827a-4240-ad87-101aa3b79874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"srmishra/crossencoder-tynybert-km1\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"srmishra/crossencoder-tynybert-km1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7aecc9ea-8244-4ee9-a3a8-28a0e7bcc4ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CrossEncoder' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Put the model in evaluation mode\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Predictions list\u001b[39;00m\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CrossEncoder' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Predictions list\n",
    "predictions = []\n",
    "\n",
    "# Disable gradient calculation for inference\n",
    "# encoded_inputs = encoded_inputs[:10]\n",
    "with torch.no_grad():\n",
    "    for encoded_input in tqdm(encoded_inputs):\n",
    "        # Move the tensors to the same device as the model\n",
    "        encoded_input = {k: v.to(model.device) for k, v in encoded_input.items()}\n",
    "        \n",
    "        # Get the model outputs\n",
    "        outputs = model(**encoded_input)\n",
    "        print(outputs)\n",
    "        # The outputs are logits, get the score by applying the appropriate activation function\n",
    "        # For regression tasks (like STS-B), you can directly use the output value as the score\n",
    "        # For classification tasks, apply a softmax function to get probabilities\n",
    "        score = outputs.logits.squeeze().item()\n",
    "        \n",
    "        # print(score)\n",
    "        predictions.append(score)\n",
    "\n",
    "# Now `predictions` holds the similarity scores for each pair of sentences\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df5003-382b-43e5-9caf-dacf516c91ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "198b02cc-4eed-41f1-aaf2-fcfcfa5f4f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1485"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f68243d-3eda-4774-b357-c5a24f8af20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = test_dataset.to_pandas()[[\"sentence1\",\"sentence2\",\"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e44f147-0abc-43b4-93d2-7d46d53b7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df[\"similar_score\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "abd682f2-e204-48ee-a2fa-fe34bd1d1493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>labels</th>\n",
       "      <th>similar_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how to unhook a ticket in term</td>\n",
       "      <td>Can anyone unboard this passenger so I can cha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how to unhook a ticket in term</td>\n",
       "      <td>What are the closest airports to SFO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.033835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do you need an e visa to transit through Brazil</td>\n",
       "      <td>Korea travel requirements</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.034878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what time does msp airport open</td>\n",
       "      <td>what are the hours of the ticket counter at Si...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.052111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is visa required for connecting flights</td>\n",
       "      <td>Korea travel requirements</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.062162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>can i assign seats on air france</td>\n",
       "      <td>can I assign seats on Air France</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.055483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>does recognize PM Platinum Medallion status fo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entry to unhook ticket in term</td>\n",
       "      <td>what is the age limit for first class?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WHAT TIME DOES MIDWAY OPEN</td>\n",
       "      <td>what time does lagos airport open</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.032597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>which terminal does use in lga</td>\n",
       "      <td>airport phone number for Atlanta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.037165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>birds as pet in cabin</td>\n",
       "      <td>can i bring a bird as a PETC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.054094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>what size kennel will fit in the cabin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.043452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Is there a change fee for MEX</td>\n",
       "      <td>Is there a change fee for MEX</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.126162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>airport phone number for Atlanta</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>how to unhook a ticket in term</td>\n",
       "      <td>skymiles transfer due to death</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.034250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>what is the terminal in cancum airport</td>\n",
       "      <td>what time does tuscon ticket counter open</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.074439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>what is the minimum connection time in atl</td>\n",
       "      <td>what is the mct for an international flight</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.057948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>how do you apply a skymiles mileage upgrade on...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>which terminal does use in lga</td>\n",
       "      <td>do ONT have a lost and found</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.056134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>How many checked bags does military get</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.049873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>can i bring an elephant</td>\n",
       "      <td>can i take a pony on the plane</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.052771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>can i use a global certificate to travel to Ha...</td>\n",
       "      <td>Can a regional certificate be applied to sxm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.038980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>fee for golf clubs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.023247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>will pax need transit visa to dehli</td>\n",
       "      <td>do you have to book a return flight if your vi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.073818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>how do i cancel one leg of a round trip</td>\n",
       "      <td>how do i cancel one leg of a round trip</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.082831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>how many bags are allowed for basic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.031366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>what is the term entry to unhook a ticket</td>\n",
       "      <td>can i check a passenger out of a connecting fl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.043464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>what is the UMNR age</td>\n",
       "      <td>what is a Unaccompanied minor for delta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.747548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>what is the special meal request ssr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.063040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>Can I change my name on my reservation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.032910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>what is the term entry to unhook a ticket</td>\n",
       "      <td>how can i check on the refund for canceled gif...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.040173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Can I use a campanion certificate Mexico</td>\n",
       "      <td>what areas can the American Express companion ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>how many pets in cabin per passenger</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.037309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>how to unhook a ticket in term</td>\n",
       "      <td>what countries have asc fees</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>entry to unhook ticket in term</td>\n",
       "      <td>what are the rules for covid ecredits</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>is visa required to travel fromm cdg</td>\n",
       "      <td>do us citizens need visa for italy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.050505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>is a visa required when traveling through to bom</td>\n",
       "      <td>do us citizens need visa for italy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.064564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>what is the bag fee to london</td>\n",
       "      <td>what is the baggage allowance for medallions</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>entry to unhook ticket in term</td>\n",
       "      <td>how do you identify a customer at risk of deni...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.021562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>can you take a pet to London</td>\n",
       "      <td>can a pet travel to lhr</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.057728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence1  \\\n",
       "0                      how to unhook a ticket in term   \n",
       "1                      how to unhook a ticket in term   \n",
       "2     do you need an e visa to transit through Brazil   \n",
       "3                     what time does msp airport open   \n",
       "4             is visa required for connecting flights   \n",
       "5                    can i assign seats on air france   \n",
       "6                 what is the unaccompanied minor fee   \n",
       "7                      entry to unhook ticket in term   \n",
       "8                          WHAT TIME DOES MIDWAY OPEN   \n",
       "9                      which terminal does use in lga   \n",
       "10                              birds as pet in cabin   \n",
       "11             how much is a UMNR fee from jfk to acc   \n",
       "12                      Is there a change fee for MEX   \n",
       "13                what is the unaccompanied minor fee   \n",
       "14                     how to unhook a ticket in term   \n",
       "15             what is the terminal in cancum airport   \n",
       "16         what is the minimum connection time in atl   \n",
       "17                what is the unaccompanied minor fee   \n",
       "18                     which terminal does use in lga   \n",
       "19                what is the unaccompanied minor fee   \n",
       "20                            can i bring an elephant   \n",
       "21  can i use a global certificate to travel to Ha...   \n",
       "22             how much is a UMNR fee from jfk to acc   \n",
       "23                will pax need transit visa to dehli   \n",
       "24            how do i cancel one leg of a round trip   \n",
       "25             how much is a UMNR fee from jfk to acc   \n",
       "26          what is the term entry to unhook a ticket   \n",
       "27                               what is the UMNR age   \n",
       "28             how much is a UMNR fee from jfk to acc   \n",
       "29             how much is a UMNR fee from jfk to acc   \n",
       "30          what is the term entry to unhook a ticket   \n",
       "31           Can I use a campanion certificate Mexico   \n",
       "32                what is the unaccompanied minor fee   \n",
       "33                     how to unhook a ticket in term   \n",
       "34                     entry to unhook ticket in term   \n",
       "35               is visa required to travel fromm cdg   \n",
       "36   is a visa required when traveling through to bom   \n",
       "37                      what is the bag fee to london   \n",
       "38                     entry to unhook ticket in term   \n",
       "39                       can you take a pet to London   \n",
       "\n",
       "                                            sentence2  labels  similar_score  \n",
       "0   Can anyone unboard this passenger so I can cha...     0.0      -0.035986  \n",
       "1                What are the closest airports to SFO     0.0      -0.033835  \n",
       "2                           Korea travel requirements     1.0       1.034878  \n",
       "3   what are the hours of the ticket counter at Si...     1.0       1.052111  \n",
       "4                           Korea travel requirements     1.0       1.062162  \n",
       "5                    can I assign seats on Air France     1.0       1.055483  \n",
       "6   does recognize PM Platinum Medallion status fo...     0.0      -0.048264  \n",
       "7              what is the age limit for first class?     0.0       0.001806  \n",
       "8                   what time does lagos airport open     1.0       1.032597  \n",
       "9                    airport phone number for Atlanta     1.0       1.037165  \n",
       "10                       can i bring a bird as a PETC     1.0       1.054094  \n",
       "11             what size kennel will fit in the cabin     0.0      -0.043452  \n",
       "12                      Is there a change fee for MEX     1.0       1.126162  \n",
       "13                   airport phone number for Atlanta     0.0      -0.003801  \n",
       "14                     skymiles transfer due to death     0.0      -0.034250  \n",
       "15          what time does tuscon ticket counter open     1.0       1.074439  \n",
       "16        what is the mct for an international flight     1.0       1.057948  \n",
       "17  how do you apply a skymiles mileage upgrade on...     0.0      -0.004616  \n",
       "18                       do ONT have a lost and found     1.0       1.056134  \n",
       "19            How many checked bags does military get     0.0      -0.049873  \n",
       "20                     can i take a pony on the plane     1.0       1.052771  \n",
       "21       Can a regional certificate be applied to sxm     1.0       1.038980  \n",
       "22                                 fee for golf clubs     0.0      -0.023247  \n",
       "23  do you have to book a return flight if your vi...     1.0       1.073818  \n",
       "24            how do i cancel one leg of a round trip     1.0       1.082831  \n",
       "25                how many bags are allowed for basic     0.0      -0.031366  \n",
       "26  can i check a passenger out of a connecting fl...     0.0      -0.043464  \n",
       "27            what is a Unaccompanied minor for delta     1.0       0.747548  \n",
       "28               what is the special meal request ssr     0.0      -0.063040  \n",
       "29             Can I change my name on my reservation     0.0      -0.032910  \n",
       "30  how can i check on the refund for canceled gif...     0.0      -0.040173  \n",
       "31  what areas can the American Express companion ...     1.0       0.993998  \n",
       "32               how many pets in cabin per passenger     0.0      -0.037309  \n",
       "33                       what countries have asc fees     0.0      -0.045276  \n",
       "34              what are the rules for covid ecredits     0.0       0.002444  \n",
       "35                 do us citizens need visa for italy     1.0       1.050505  \n",
       "36                 do us citizens need visa for italy     1.0       1.064564  \n",
       "37       what is the baggage allowance for medallions     1.0       0.941641  \n",
       "38  how do you identify a customer at risk of deni...     0.0      -0.021562  \n",
       "39                            can a pet travel to lhr     1.0       1.057728  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7909bfb-8848-43bb-bb0c-7b5582676512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence1                      will pax need transit visa to dehli\n",
       "sentence2        do you have to book a return flight if your vi...\n",
       "labels                                                         1.0\n",
       "similar_score                                             1.072025\n",
       "Name: 23, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df.iloc[23]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5278d8-6010-4f2a-aebe-4bf7ce1e1ed1",
   "metadata": {},
   "source": [
    "## Calculate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32b431b6-ca4f-4d69-b3ad-544df624f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df['binarized'] = predicted_df['similar_score'].apply(lambda x: 1.0 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1c6c81b0-e887-4a24-ada0-de37a2ff9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9eedd657-709e-4336-b0e0-0696396b32bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(predicted_df['labels'], predicted_df['binarized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c8d16fe5-d886-4c4e-851b-024402d9f6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9986824769433466"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(predicted_df['labels'], predicted_df['binarized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cadff379-fb5f-4f15-89f2-70361959ca7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993265993265993"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predicted_df['labels'], predicted_df['binarized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "20e57dce-1a2c-4966-bc68-7d616ea61a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999340804218853"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(predicted_df['labels'], predicted_df['binarized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7992058f-481f-48a3-83ed-2810c3916fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4286500-2f89-48c9-8611-ef38c50773de",
   "metadata": {},
   "source": [
    "## Cross Encoder with Sentence-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1acd6eb0-1dee-49a1-874c-347b8f8f8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import CrossEncoder\n",
    "\n",
    "# # Initialize the cross-encoder model\n",
    "# cross_encoder = CrossEncoder('cross-encoder/stsb-roberta-large')\n",
    "\n",
    "# # Step 1: Retrieve candidate documents using Elasticsearch or another IR system\n",
    "# candidate_documents = retrieve_candidates(query)\n",
    "\n",
    "# # Step 2: Re-rank candidates using the cross encoder\n",
    "# pair_list = [(query, doc) for doc in candidate_documents]\n",
    "# scores = cross_encoder.predict(pair_list)\n",
    "\n",
    "# # Sort the documents by their score in descending order\n",
    "# ranked_documents = sorted(zip(candidate_documents, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# # Return the top N results\n",
    "# top_results = ranked_documents[:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a46425-5361-4450-919c-2087111d9bce",
   "metadata": {},
   "source": [
    "Up-sampling the Minority Class: This involves randomly duplicating examples in the minority class (label 1 in your case) to achieve a balance between the two classes. This can be done manually or using libraries like imblearn in Python.\n",
    "*****************\n",
    "```python\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "```\n",
    "****************\n",
    "\n",
    "Where X is your feature matrix and y is your array of labels.\n",
    "\n",
    "Down-sampling the Majority Class: This method involves randomly removing examples from the majority class (label 0) to balance the dataset. Again, this can be done manually or using imblearn.\n",
    "\n",
    "****************\n",
    "```python\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "```\n",
    "****************\n",
    "\n",
    "\n",
    "Synthetic Data Generation: Techniques such as SMOTE (Synthetic Minority Over-sampling Technique) can generate synthetic examples for the minority class.\n",
    "\n",
    "****************\n",
    "```python\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "```\n",
    "****************\n",
    "\n",
    "Combining Over and Under Sampling: You can combine both over-sampling the minority class and under-sampling the majority class to achieve a balance.\n",
    "\n",
    "****************\n",
    "```python\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "```\n",
    "****************\n",
    "\n",
    "Adjusting Class Weights: Some algorithms allow you to adjust the weights of classes to handle imbalanced data. For instance, many implementations of classifiers in scikit-learn have a class_weight parameter.\n",
    "\n",
    "****************\n",
    "```python\n",
    "    \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "\n",
    "```\n",
    "\n",
    "****************\n",
    "\n",
    "Custom Loss Functions: If you are using deep learning, you can design custom loss functions that penalize the misclassification of the minority class more than the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baceeec9-c0c7-46ac-9e73-baafc3a431fa",
   "metadata": {},
   "source": [
    "## Calculate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44f2eb-3035-4595-a958-6f7c89afa5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "# Example DataFrame\n",
    "# data = {'sentence': ['This is sentence 1', 'Another sentence', 'Yet another sentence'],\n",
    "#         'label': [1, 0, 1],\n",
    "#         'predicted_label': [1, 1, 0]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate precision, recall, and accuracy\n",
    "precision = precision_score(df['label'], df['predicted_label'])\n",
    "recall = recall_score(df['label'], df['predicted_label'])\n",
    "accuracy = accuracy_score(df['label'], df['predicted_label'])\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7fb0f2-1b42-4c7d-a5a4-5b634033f3fb",
   "metadata": {},
   "source": [
    "## Comparion of model After finetuning vs Loading same version from Huggingface hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f9bdf4e8-a796-4bf6-b0a0-74349f7e1882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pjbhaumik/crossencoder-km1\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"pjbhaumik/crossencoder-km1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f1d91629-b583-4172-8f60-6a55beac7d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./crossencoder_km_mini2')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('./crossencoder_km_mini2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6d3af32e-c209-40c1-b273-4885ab6883b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./joecrossencoder/crossencoder_model_v4\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./joecrossencoder/crossencoder_model_v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c438649-1eed-4747-a8f0-4f60cf2ff5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "87d9f6eb-7a21-41ee-aa0f-ddfba547c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "48334a3b-2025-42f9-8f2d-bafe8ab96d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentences(sentence1, sentence2):\n",
    "    return tokenizer(sentence1, sentence2, return_tensors='pt', truncation=True, padding='max_length')\n",
    "\n",
    "\n",
    "sentence_pairs = [\n",
    "    ('what is the UMNR fee', 'how many pets can i have')\n",
    "    \n",
    "]\n",
    "\n",
    "encoded_inputs = [encode_sentences(pair[0], pair[1]) for pair in sentence_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e5b628ab-85d1-4685-822d-61f3e7cba1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-0.1989]]), hidden_states=None, attentions=None)\n",
      "[-0.19885557889938354]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Predictions list\n",
    "predictions = []\n",
    "\n",
    "# Disable gradient calculation for inference\n",
    "# encoded_inputs = encoded_inputs[:10]\n",
    "with torch.no_grad():\n",
    "    for encoded_input in tqdm(encoded_inputs):\n",
    "        # Move the tensors to the same device as the model\n",
    "        encoded_input = {k: v.to(model.device) for k, v in encoded_input.items()}\n",
    "        \n",
    "        # Get the model outputs\n",
    "        outputs = model(**encoded_input)\n",
    "        print(outputs)\n",
    "        # The outputs are logits, get the score by applying the appropriate activation function\n",
    "        # For regression tasks (like STS-B), you can directly use the output value as the score\n",
    "        # For classification tasks, apply a softmax function to get probabilities\n",
    "        score = outputs.logits.squeeze().item()\n",
    "        \n",
    "        # print(score)\n",
    "        predictions.append(score)\n",
    "\n",
    "# Now `predictions` holds the similarity scores for each pair of sentences\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "de57183f-ab7e-4e38-8461-2d53b4e4dfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git: 'lfs' is not a git command. See 'git --help'.\n",
      "\n",
      "The most similar command is\n",
      "\tlog\n",
      "fatal: destination path 'crossencoder-km1' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git lfs install\n",
    "!git clone https://huggingface.co/pjbhaumik/crossencoder-km1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9a06bef6-4011-4141-b458-f47f8881f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir joecrossencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0c8fe74c-678e-45b0-8381-ef6d7a5371be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/603642/Library/CloudStorage/OneDrive-DeltaAirLines/Desktop/Data/RES_KM_EXP/joecrossencoder\n"
     ]
    }
   ],
   "source": [
    "cd joecrossencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4df534b0-cd56-4597-8402-7d895f8392d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git: 'lfs' is not a git command. See 'git --help'.\n",
      "\n",
      "The most similar command is\n",
      "\tlog\n",
      "Cloning into 'crossencoder-km1'...\n",
      "remote: Enumerating objects: 24, done.\u001b[K\n",
      "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
      "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
      "remote: Total 24 (delta 4), reused 0 (delta 0), pack-reused 3\u001b[K\n",
      "Unpacking objects: 100% (24/24), 319.20 KiB | 645.00 KiB/s, done.\n",
      "git-lfs filter-process: git-lfs: command not found\n",
      "fatal: the remote end hung up unexpectedly\n",
      "warning: Clone succeeded, but checkout failed.\n",
      "You can inspect what was checked out with 'git status'\n",
      "and retry with 'git restore --source=HEAD :/'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git lfs install\n",
    "!git clone https://huggingface.co/pjbhaumik/crossencoder-km1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3a74b55c-0857-4ea0-88bb-4d7839835aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/603642/Library/CloudStorage/OneDrive-DeltaAirLines/Desktop/Data/RES_KM_EXP\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc45deef-0d26-46a6-918b-6e5b5bbb6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pairs = [\n",
    "    (\"What is the PETC eligibility\", \"can i bring a kitten on my flight from ATL to SLC\"),\n",
    "    (\"what is the UMNR fee\", \"how many pets can i have\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2c21fe48-785a-45e0-a84f-4718a3e453ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder,SentenceTransformer\n",
    "model = CrossEncoder(\"srmishra/crossencoder-tynybert-km1\",num_labels=1)\n",
    "scores = model.predict(sentence_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bdb3d595-d681-4737-8275-542331314d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7412276 , 0.49759802], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14eaa396-cf8b-421b-8b1b-68cefb49e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the CrossEncoder model\n",
    "model = CrossEncoder(\"srmishra/crossencoder-tynybert-km1\")\n",
    "\n",
    "# Load the tokenizer that matches the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"srmishra/crossencoder-tynybert-km1\")\n",
    "\n",
    "# Example sentence pairs\n",
    "sentence_pairs = [\n",
    "    (\"What is the PETC eligibility\", \"can i bring a kitten on my flight from ATL to SLC\"),\n",
    "    (\"what is the UMNR fee\", \"how many pets can i have\")\n",
    "]\n",
    "\n",
    "# Tokenize the sentence pairs\n",
    "tokenized_pairs = [tokenizer(pair[0], pair[1], truncation=True, return_tensors=\"pt\") for pair in sentence_pairs]\n",
    "\n",
    "# # Predict the scores for the tokenized sentence pairs\n",
    "# scores = []\n",
    "# for tokenized_input in tokenized_pairs:\n",
    "#     score = model.predict([(tokenized_input['input_ids'].squeeze().tolist(),\n",
    "#                             tokenized_input['attention_mask'].squeeze().tolist())], convert_to_tensor=True)\n",
    "#     scores.append(score)\n",
    "\n",
    "# # Flatten the scores list (since it's a list of lists with one element each)\n",
    "# scores = [score[0] for score in scores]\n",
    "\n",
    "# # Output the scores\n",
    "# print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5dc612e4-0d47-4e29-84bc-60e672db34d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7412276  0.49759802]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Initialize the model with the model name and additional arguments\n",
    "model = CrossEncoder(\"srmishra/crossencoder-tynybert-km1\" )\n",
    "# Predict the scores for the sentence pairs\n",
    "scores = model.predict(sentence_pairs)\n",
    "\n",
    "# Output the scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "872e1266-f9e3-490c-9e84-01acd591501d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGITS: tensor([[1.0524]])\n",
      "FINAL SCORES: tensor([0.7412])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer and model from Hugging Face Transformers\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"srmishra/crossencoder-tynybert-km1\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"srmishra/crossencoder-tynybert-km1\")\n",
    "\n",
    "# Example sentence pairs\n",
    "sentence_pairs = [\n",
    "    (\"What is the PETC eligibility\", \"can i bring a kitten on my flight from ATL to SLC\"),\n",
    "    (\"what is the UMNR fee\", \"how many pets can i have\")\n",
    "]\n",
    "\n",
    "# Tokenize and encode the sentence pairs for the model\n",
    "encoded_input = tokenizer(sentence_pairs[0][0], sentence_pairs[0][1], return_tensors='pt', truncation=True)\n",
    "with torch.no_grad():\n",
    "    # Get model predictions (logits)\n",
    "    logits = model(**encoded_input).logits\n",
    "    print(f\"LOGITS: {logits}\")\n",
    "\n",
    "# Check the number of output classes\n",
    "num_labels = model.config.num_labels\n",
    "# print(num_labels)\n",
    "if num_labels == 1:\n",
    "    # For binary classification with a single output neuron\n",
    "    scores = torch.sigmoid(logits)[:, 0]  # Apply sigmoid to get scores between 0 and 1\n",
    "\n",
    "\n",
    "# Output the scores\n",
    "print(f\"FINAL SCORES: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36cc4a43-fd76-4f84-9a6e-dd2c7aa3a7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7408])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.tensor([1.05]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2e7949c6-dda1-45f0-a9c7-40b4d6cf4eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4978])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.tensor([-0.009]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f075c7f-b6b5-46d6-bdf5-aa78d929d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv(\"/Users/603642/Downloads/Output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03d1d05-3485-48c0-aca5-dfc782f7cf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 761 entries, 0 to 760\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   embedding           761 non-null    object \n",
      " 1   question            761 non-null    object \n",
      " 2   response_x          761 non-null    object \n",
      " 3   response_id         761 non-null    int64  \n",
      " 4   airline             761 non-null    object \n",
      " 5   tags                761 non-null    object \n",
      " 6   best                232 non-null    object \n",
      " 7   scores              761 non-null    object \n",
      " 8   similar_question    232 non-null    object \n",
      " 9   rerank_score        224 non-null    float64\n",
      " 10  response_id_rerank  224 non-null    float64\n",
      " 11  _id                 224 non-null    float64\n",
      " 12  response_y          224 non-null    object \n",
      "dtypes: float64(3), int64(1), object(9)\n",
      "memory usage: 77.4+ KB\n"
     ]
    }
   ],
   "source": [
    "output.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f271966-12f6-4fce-90f2-a0aff91d3463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(761, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c7985f9-2bad-48cf-8852-2560aec82e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output['response_id'] == output['best']).sum() / (output.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5fffb2c-a989-4635-b373-46a7892d6e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"similar_question\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0e7bd47f-c844-454f-b1e2-9113ce528de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>similar_question</th>\n",
       "      <th>response_x</th>\n",
       "      <th>response_y</th>\n",
       "      <th>scores</th>\n",
       "      <th>best</th>\n",
       "      <th>response_id</th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how much is a UMNR fee from jfk to acc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p class=\"ng-tns-c32-1\"&gt;150 USD/CAD/EUR for ea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>what is the unaccompanied minor fee</td>\n",
       "      <td>&lt;p class=\"ng-tns-c32-1\"&gt;150 USD/CAD/EUR for ea...</td>\n",
       "      <td>&lt;p class=\"ng-tns-c32-1\"&gt;150 USD/CAD/EUR for ea...</td>\n",
       "      <td>['what is the unaccompanied minor fee', 3.5607...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the UMNR fee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p class=\"ng-tns-c32-1\"&gt;150 USD/CAD/EUR for ea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the term entry to unhook a ticket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;&amp;gt;T/X(pax #)&lt;/p&gt;\\n&lt;p&gt;Unhook Passenger 1.1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how to unhook a ticket in term</td>\n",
       "      <td>how to unhook a tkt in term</td>\n",
       "      <td>&lt;p&gt;&amp;gt;T/X(pax #)&lt;/p&gt;\\n&lt;p&gt;Unhook Passenger 1.1...</td>\n",
       "      <td>&lt;p&gt;&amp;gt;T/X(pax #)&lt;/p&gt;\\n&lt;p&gt;Unhook Passenger 1.1...</td>\n",
       "      <td>['how to unhook a tkt in term', 0.865902602672...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>can a passenger use ecredits to purchase baggage</td>\n",
       "      <td>can a passenger prepay for luggage</td>\n",
       "      <td>&lt;p&gt;eCredits or paper vouchers cannot be applie...</td>\n",
       "      <td>&lt;p&gt;No, customers cannot pre-pay for baggage in...</td>\n",
       "      <td>['can a passenger prepay for luggage', 0.98735...</td>\n",
       "      <td>325</td>\n",
       "      <td>1225</td>\n",
       "      <td>325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>ecredit use on other person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;eCredit transferability varies based on eCr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1234</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>latam carry on bag</td>\n",
       "      <td>latam carry on</td>\n",
       "      <td>&lt;p&gt;Customers with Promo, Light, Plus, or Top f...</td>\n",
       "      <td>&lt;p&gt;Customers with Promo, Light, Plus, or Top f...</td>\n",
       "      <td>['latam carry on', 2.616466999053955, 1255]</td>\n",
       "      <td>1255</td>\n",
       "      <td>1255</td>\n",
       "      <td>1255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>booking on Kenya airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Direct Access must be used to book award tr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1282</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>award travel on kenya airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Direct Access must be used to book award tr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1282</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>761 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0              how much is a UMNR fee from jfk to acc   \n",
       "1                 what is the unaccompanied minor fee   \n",
       "2                                what is the UMNR fee   \n",
       "3           what is the term entry to unhook a ticket   \n",
       "4                      how to unhook a ticket in term   \n",
       "..                                                ...   \n",
       "756  can a passenger use ecredits to purchase baggage   \n",
       "757                       ecredit use on other person   \n",
       "758                                latam carry on bag   \n",
       "759                          booking on Kenya airways   \n",
       "760                     award travel on kenya airways   \n",
       "\n",
       "                        similar_question  \\\n",
       "0                                    NaN   \n",
       "1    what is the unaccompanied minor fee   \n",
       "2                                    NaN   \n",
       "3                                    NaN   \n",
       "4            how to unhook a tkt in term   \n",
       "..                                   ...   \n",
       "756   can a passenger prepay for luggage   \n",
       "757                                  NaN   \n",
       "758                       latam carry on   \n",
       "759                                  NaN   \n",
       "760                                  NaN   \n",
       "\n",
       "                                            response_x  \\\n",
       "0    <p class=\"ng-tns-c32-1\">150 USD/CAD/EUR for ea...   \n",
       "1    <p class=\"ng-tns-c32-1\">150 USD/CAD/EUR for ea...   \n",
       "2    <p class=\"ng-tns-c32-1\">150 USD/CAD/EUR for ea...   \n",
       "3    <p>&gt;T/X(pax #)</p>\\n<p>Unhook Passenger 1.1...   \n",
       "4    <p>&gt;T/X(pax #)</p>\\n<p>Unhook Passenger 1.1...   \n",
       "..                                                 ...   \n",
       "756  <p>eCredits or paper vouchers cannot be applie...   \n",
       "757  <p>eCredit transferability varies based on eCr...   \n",
       "758  <p>Customers with Promo, Light, Plus, or Top f...   \n",
       "759  <p>Direct Access must be used to book award tr...   \n",
       "760  <p>Direct Access must be used to book award tr...   \n",
       "\n",
       "                                            response_y  \\\n",
       "0                                                  NaN   \n",
       "1    <p class=\"ng-tns-c32-1\">150 USD/CAD/EUR for ea...   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4    <p>&gt;T/X(pax #)</p>\\n<p>Unhook Passenger 1.1...   \n",
       "..                                                 ...   \n",
       "756  <p>No, customers cannot pre-pay for baggage in...   \n",
       "757                                                NaN   \n",
       "758  <p>Customers with Promo, Light, Plus, or Top f...   \n",
       "759                                                NaN   \n",
       "760                                                NaN   \n",
       "\n",
       "                                                scores  best  response_id  \\\n",
       "0                                                   []   NaN            3   \n",
       "1    ['what is the unaccompanied minor fee', 3.5607...     3            3   \n",
       "2                                                   []   NaN            3   \n",
       "3                                                   []   NaN            4   \n",
       "4    ['how to unhook a tkt in term', 0.865902602672...     4            4   \n",
       "..                                                 ...   ...          ...   \n",
       "756  ['can a passenger prepay for luggage', 0.98735...   325         1225   \n",
       "757                                                 []   NaN         1234   \n",
       "758        ['latam carry on', 2.616466999053955, 1255]  1255         1255   \n",
       "759                                                 []   NaN         1282   \n",
       "760                                                 []   NaN         1282   \n",
       "\n",
       "        _id  \n",
       "0       NaN  \n",
       "1       3.0  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       4.0  \n",
       "..      ...  \n",
       "756   325.0  \n",
       "757     NaN  \n",
       "758  1255.0  \n",
       "759     NaN  \n",
       "760     NaN  \n",
       "\n",
       "[761 rows x 8 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[[\"question\",\"similar_question\",\"response_x\",\"response_y\",\"scores\",\"best\",\"response_id\",\"_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda1d24-f857-4ece-8a3a-9b50c426d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b79fb-59a3-41c8-9e3c-aad311ffd697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00aa643-8e09-447c-9036-670fa5f90e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a95c3091-a2e8-4319-a86e-1f575aedcdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>response_x</th>\n",
       "      <th>response_y</th>\n",
       "      <th>similar_question</th>\n",
       "      <th>rerank_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [question, response_x, response_y, similar_question, rerank_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_examples = output[output['response_id'] == output['best']]\n",
    "positive_examples[['question', 'response_x', 'response_y', 'similar_question', 'rerank_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b693571-7d10-4e78-b4bd-0dd5d65ce64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(529, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[output.scores==\"[]\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2d35dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3e6b954a-902c-4238-a073-131215df92da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model and tokenizer\n",
    "model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Freeze all the parameters in the model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the last layer (classifier)\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2005d3-4316-4a4c-8134-5f1db48e3866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da92ab-6016-408e-a846-6b74583231f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0a84e-45a3-4ef1-8a03-8cd84bd2b9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "aa04a412-6162-45a4-99f1-a3cf518e8bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0309, -0.0254, -0.0326,  0.0325, -0.0445, -0.0274, -0.0233, -0.0275,\n",
      "         -0.0285, -0.0410,  0.0389, -0.0270,  0.0247, -0.0473, -0.0297,  0.0295,\n",
      "          0.0263,  0.0360,  0.0242,  0.0256, -0.0207, -0.0246, -0.0422,  0.0272,\n",
      "         -0.0272,  0.0253,  0.0228, -0.0336,  0.0226,  0.0253,  0.0354, -0.0330,\n",
      "          0.0339, -0.0499, -0.0318, -0.0349, -0.0218,  0.0247, -0.0237, -0.0456,\n",
      "         -0.0485, -0.0240,  0.0488, -0.0251, -0.0337,  0.0256,  0.0434,  0.0260,\n",
      "          0.0267, -0.0232,  0.0307, -0.0345, -0.0290,  0.0346, -0.0276,  0.0360,\n",
      "          0.0301,  0.0507, -0.0235, -0.0239,  0.0264,  0.0415, -0.0319, -0.0235,\n",
      "          0.0225, -0.0236, -0.0284,  0.0344, -0.0451,  0.0247,  0.0324,  0.0218,\n",
      "         -0.0245, -0.0250,  0.0238,  0.0456,  0.0247,  0.0361, -0.0267, -0.0299,\n",
      "         -0.0465, -0.0388, -0.0366, -0.0306, -0.0304, -0.0351, -0.0269, -0.0295,\n",
      "         -0.0525,  0.0319,  0.0250, -0.0205,  0.0323, -0.0508,  0.0267,  0.0536,\n",
      "         -0.0234, -0.0258, -0.0279,  0.0267,  0.0496,  0.0275, -0.0283, -0.0384,\n",
      "          0.0257,  0.0399,  0.0298,  0.0271, -0.0307,  0.0329, -0.0609,  0.0298,\n",
      "         -0.0258,  0.0571,  0.0196, -0.0344, -0.0235,  0.0343,  0.0491, -0.0328,\n",
      "          0.0275,  0.0480,  0.0237,  0.0244,  0.0265, -0.0223, -0.0226,  0.0324,\n",
      "         -0.0336, -0.0454, -0.0365,  0.0499,  0.0452,  0.0250, -0.0481, -0.0260,\n",
      "         -0.0470,  0.0220, -0.0392, -0.0226,  0.0336, -0.0403, -0.0341,  0.0293,\n",
      "         -0.0238, -0.0259, -0.0220,  0.0284,  0.0245,  0.0431, -0.0325, -0.0226,\n",
      "         -0.0389,  0.0450,  0.0267, -0.0249, -0.0367, -0.0332, -0.0277,  0.0289,\n",
      "         -0.0296,  0.0211,  0.0505, -0.0374,  0.0212,  0.0365,  0.0236,  0.0233,\n",
      "         -0.0246, -0.0189,  0.0346, -0.0414, -0.0299,  0.0341, -0.0262,  0.0392,\n",
      "          0.0290, -0.0247, -0.0226,  0.0319,  0.0277,  0.0274,  0.0252,  0.0311,\n",
      "         -0.0485,  0.0275, -0.0323, -0.0235, -0.0232, -0.0421,  0.0430,  0.0248,\n",
      "          0.0288,  0.0363,  0.0430,  0.0300, -0.0403, -0.0267, -0.0417, -0.0209,\n",
      "         -0.0217,  0.0422, -0.0297,  0.0210,  0.0370, -0.0273,  0.0301, -0.0344,\n",
      "         -0.0224,  0.0266, -0.0326,  0.0343, -0.0417,  0.0338, -0.0327, -0.0290,\n",
      "         -0.0236, -0.0363,  0.0229, -0.0246, -0.0288, -0.0294, -0.0392,  0.0209,\n",
      "          0.0273,  0.0295,  0.0429,  0.0228,  0.0360, -0.0388,  0.0262, -0.0242,\n",
      "          0.0325, -0.0523,  0.0298, -0.0230, -0.0259,  0.0333, -0.0444, -0.0249,\n",
      "          0.0406,  0.0280, -0.0352, -0.0277,  0.0368,  0.0242, -0.0229, -0.0306,\n",
      "          0.0256, -0.0262,  0.0424, -0.0246,  0.0238, -0.0258, -0.0379, -0.0298,\n",
      "          0.0319,  0.0421,  0.0263,  0.0491,  0.0442,  0.0319,  0.0249,  0.0297,\n",
      "         -0.0358, -0.0289,  0.0242,  0.0400, -0.0273, -0.0427, -0.0233, -0.0234,\n",
      "          0.0300,  0.0567, -0.0238,  0.0282, -0.0354, -0.0267,  0.0319,  0.0569,\n",
      "         -0.0463,  0.0330,  0.0249, -0.0271, -0.0319,  0.0298,  0.0493,  0.0401,\n",
      "          0.0321,  0.0261, -0.0358, -0.0411,  0.0319, -0.0285, -0.0271,  0.0390,\n",
      "          0.0278,  0.0232, -0.0219,  0.0285, -0.0458,  0.0245, -0.0401,  0.0310,\n",
      "         -0.0303, -0.0303, -0.0295, -0.0345,  0.0220, -0.0404, -0.0197, -0.0214,\n",
      "          0.0271, -0.0392, -0.0293, -0.0241, -0.0266, -0.0224, -0.0270, -0.0265,\n",
      "         -0.0476,  0.0245,  0.0265, -0.0342,  0.0334,  0.0244, -0.0319, -0.0423,\n",
      "          0.0436,  0.0299, -0.0214,  0.0217,  0.0263, -0.0241,  0.0517,  0.0237,\n",
      "          0.0265, -0.0322, -0.0364,  0.0238, -0.0290, -0.0417, -0.0279,  0.0301,\n",
      "         -0.0284,  0.0292, -0.0423, -0.0277,  0.0231,  0.0231,  0.0309, -0.0252,\n",
      "         -0.0300,  0.0431, -0.0279,  0.0262, -0.0561, -0.0226,  0.0232,  0.0439,\n",
      "         -0.0378,  0.0252,  0.0228, -0.0286, -0.0374, -0.0273,  0.0232,  0.0239,\n",
      "          0.0251, -0.0475,  0.0419,  0.0262,  0.0384,  0.0498,  0.0249,  0.0301,\n",
      "          0.0295, -0.0202, -0.0323,  0.0224, -0.0234, -0.0264, -0.0280, -0.0239]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.classifier.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c597b-b799-4640-8fe4-cada46274d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a new Bi-LSTM layer to be added on top of the MiniLM model\n",
    "class BiLSTMHead(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels):\n",
    "        super().__init__()\n",
    "        self.bi_lstm = nn.LSTM(hidden_size, hidden_size // 2, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        lstm_output, _ = self.bi_lstm(hidden_states)\n",
    "        # We just want the last hidden state from the sequence for classification\n",
    "        lstm_output = lstm_output[:, -1, :]\n",
    "        logits = self.classifier(lstm_output)\n",
    "        return logits\n",
    "\n",
    "# Assuming the hidden size is 384 for MiniLM-L-6-v2 and we have a binary classification problem\n",
    "hidden_size = 384\n",
    "num_labels = 2\n",
    "\n",
    "# Replace the classifier with the new Bi-LSTM head\n",
    "model.classifier = BiLSTMHead(hidden_size, num_labels)\n",
    "\n",
    "# Now you can fine-tune the model with your data and preferred optimization setup\n",
    "# ...\n",
    "\n",
    "# Remember to unfreeze layers gradually if you want to fine-tune more than the Bi-LSTM and last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d0d0f0-a36b-4ce0-a5da-76abcfbd1f06",
   "metadata": {},
   "source": [
    "## Imabalance Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23e05c52-38f5-4094-bde0-2af16b818a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0.0    1500\n",
       "1.0     500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_df = pd.concat([positive_df.iloc[:500],negative_df.iloc[:1500]])\n",
    "imb_df[\"review\"] = imb_df[\"sentence1\"]+\" \"+imb_df[\"sentence1\"]\n",
    "imb_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4144cffd-d0f9-403b-ac4c-a911f4243b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "# Assuming you have a DataFrame `df` with columns 'review' and 'label' (0 for negative, 1 for positive)\n",
    "# Prepare the data\n",
    "train,validation = train_test_split(imb_df, stratify=imb_df['labels'])\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "weights = torch.tensor(class_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "116cbffb-b453-4eb9-be45-226013d41aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6667, 2.0000])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "557e0574-02cf-428c-b2e9-e14f82bffea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eaba7900f034a259b24fa5d7b50bbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc2a408bdbc4f4ebe9f266206861a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "def encode(examples):\n",
    "    return tokenizer(examples['review'], truncation=True, padding='max_length',max_length=128)\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "# test_dataset = Dataset.from_pandas(test)\n",
    "val_dataset = Dataset.from_pandas(validation)\n",
    "\n",
    "train_encoded = train_dataset.map(encode, batched=True)\n",
    "val_encoded = val_dataset.map(encode, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683ead2-50c6-4f24-9374-ab34eb169280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "54e161d8-b357-43bb-8fbf-ec9c16a125af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4238009-d1f7-408b-b0ab-365439685996",
   "metadata": {},
   "source": [
    "- Use the weights in compute loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "96553e98-5821-47c5-accd-84fa5bbccf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        # print(inputs)\n",
    "        outputs = model(**inputs)\n",
    "        print(outputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss (suppose one has 3 labels with different weights)\n",
    "        \n",
    "        loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "        logger.info(\"loss function\")\n",
    "        loss = loss_fct(logits.view(-1, self.model.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c9a426e3-5ce1-41b6-bb6d-b63f6c4be800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fct = nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "69159f0e-4bae-4128-b572-d8b2e4af24d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_encoded,\n",
    "    eval_dataset=val_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "232d7334-449d-4be0-b202-71cf5aafc777",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([8])) must be the same as input size (torch.Size([8, 2]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/genai/lib/python3.9/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/genai/lib/python3.9/site-packages/transformers/trainer.py:1869\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1875\u001b[0m ):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/genai/lib/python3.9/site-packages/transformers/trainer.py:2772\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2772\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2775\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[98], line 16\u001b[0m, in \u001b[0;36mCustomTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m     13\u001b[0m labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print(inputs)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs)\n\u001b[1;32m     18\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/genai/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/genai/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/genai/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1602\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1601\u001b[0m         loss_fct \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss()\n\u001b[0;32m-> 1602\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1604\u001b[0m     output \u001b[38;5;241m=\u001b[39m (logits,) \u001b[38;5;241m+\u001b[39m outputs[\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/genai/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/genai/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/genai/lib/python3.9/site-packages/torch/nn/modules/loss.py:725\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/genai/lib/python3.9/site-packages/torch/nn/functional.py:3197\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m-> 3197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([8])) must be the same as input size (torch.Size([8, 2]))"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a3b5ba-0891-4523-bc80-bdd64fb881ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f183ec6-9a33-44ba-bd8a-f446b790f7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3000 entries, 0 to 2004\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   sentence1  3000 non-null   object \n",
      " 1   sentence2  3000 non-null   object \n",
      " 2   labels     3000 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 93.8+ KB\n"
     ]
    }
   ],
   "source": [
    "imb_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2499538a-c977-4d77-bed9-9cdf77497fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_df[\"review\"] = imb_df[\"sentence1\"]+' '+imb_df[\"sentence1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb0d02-50dd-45ff-a071-f224f2f74507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39de3ed-53a1-4e1e-9014-1b78e2d3c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_samples / (n_classes * np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41b61e57-6d23-4b11-bc50-f040a4f8d784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5 , 0.75])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import numpy as np\n",
    ">>> from sklearn.utils.class_weight import compute_class_weight\n",
    ">>> y = [1, 1, 1, 1, 0, 0]\n",
    ">>> compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "973fdf2a-39ad-4ea0-90ad-0856a989008b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a50735-194a-4322-a70d-6dd024bbf5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
